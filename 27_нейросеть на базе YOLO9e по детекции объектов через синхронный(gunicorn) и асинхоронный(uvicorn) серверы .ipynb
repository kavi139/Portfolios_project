{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "r7jMz9vsPdKH",
        "Zt0aCCjDPNDT",
        "0_eBNIOPP3SU",
        "rymdHblyixLt",
        "LTyI_Si9PxcR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Задание:\n",
        "1. Создайте виртуальную машину (можно без GPU)\n",
        "2. Напишите скрипт, использующий \"тяжелую\" модель (YOLO, MASK-RCNN или создайте произвольную большую архитектуру по любому из занятий). Цель: долгое время predict'а модели. Либо отправлять на сервер батч изображений\n",
        "3. Проведите тестирования обращения к Вашей моделе, развернутой на WSGI и на ASGI серверах\n",
        "4. Ответом на ДЗ может быть таблица с результатами тестирования"
      ],
      "metadata": {
        "id": "YrfY6xnmsInT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Используемые библиотеки\n",
        "%%capture\n",
        "!pip install fastapi python-multipart ultralytics uvicorn gunicorn"
      ],
      "metadata": {
        "id": "XbagQLjmsnzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "# Модель и тестовые данные\n",
        "gdown.download('https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov9e.pt', None, quiet=True)\n",
        "gdown.download('https://storage.yandexcloud.net/aiueducation/Content/knowledge/test_images.zip', None, quiet=True)\n",
        "!unzip -qo test_images.zip"
      ],
      "metadata": {
        "id": "zHCWFwPqY_8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# '2. Напишите скрипт, использующий \"тяжелую\" модель'"
      ],
      "metadata": {
        "id": "r7jMz9vsPdKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file flaskapp.py\n",
        "import io\n",
        "import time\n",
        "from flask import Flask, request, jsonify\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Загрузка модели\n",
        "model = YOLO('yolov9e.pt')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if 'images' in request.files:\n",
        "        images = request.files.getlist('images')\n",
        "        # time.sleep(1)\n",
        "        objects_info_all = []\n",
        "        processing_times = []\n",
        "\n",
        "        for image in images:\n",
        "            image = Image.open(image)\n",
        "            if image.mode != \"RGB\":\n",
        "                image = image.convert(\"RGB\")\n",
        "\n",
        "            start_time = time.time()\n",
        "            results = model(image)\n",
        "            end_time = time.time()\n",
        "\n",
        "            processing_time = end_time - start_time\n",
        "            processing_times.append(processing_time)\n",
        "\n",
        "            detections = results[0].boxes\n",
        "\n",
        "            objects_info = []\n",
        "            for det in detections:\n",
        "                cls_id = int(det.cls)\n",
        "                cls_name = model.names[cls_id]\n",
        "                score = float(det.conf) * 100\n",
        "\n",
        "                objects_info.append({\n",
        "                    'class_id': cls_id,\n",
        "                    'class_name': cls_name,\n",
        "                    'score': score\n",
        "                })\n",
        "\n",
        "            objects_info_all.append({\n",
        "                'objects': objects_info,\n",
        "                'processing_time': processing_time\n",
        "            })\n",
        "\n",
        "        total_time = sum(processing_times)\n",
        "        average_time = total_time / len(processing_times)\n",
        "\n",
        "        return jsonify({\n",
        "            'results': objects_info_all,\n",
        "            'total_processing_time': total_time,\n",
        "            'average_processing_time': average_time\n",
        "        })\n",
        "\n",
        "    return jsonify({'ошибка': 'Изображения не предоставлены'}), 400\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeXlqVmFl3b3",
        "outputId": "8783ae74-897c-49d1-f19b-ead5de2f32f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing flaskapp.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file fastapiapp.py\n",
        "import io\n",
        "import time\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.responses import JSONResponse\n",
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Загрузка модели\n",
        "model = YOLO('yolov9e.pt')  # замените на реальный путь к вашей модели\n",
        "\n",
        "class PredictionResult(BaseModel):\n",
        "    class_id: int\n",
        "    class_name: str\n",
        "    score: float\n",
        "\n",
        "class ImageResult(BaseModel):\n",
        "    objects: List[PredictionResult]\n",
        "    processing_time: float\n",
        "\n",
        "class BatchResult(BaseModel):\n",
        "    results: List[ImageResult]\n",
        "    total_processing_time: float\n",
        "    average_processing_time: float\n",
        "\n",
        "@app.post(\"/predict\", response_model=BatchResult)\n",
        "async def predict(images: List[UploadFile] = File(...)):\n",
        "    objects_info_all = []\n",
        "    processing_times = []\n",
        "\n",
        "    for image in images:\n",
        "        image_data = await image.read()\n",
        "        image = Image.open(io.BytesIO(image_data))\n",
        "        if image.mode != \"RGB\":\n",
        "            image = image.convert(\"RGB\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        results = model(image)\n",
        "        end_time = time.time()\n",
        "\n",
        "        processing_time = end_time - start_time\n",
        "        processing_times.append(processing_time)\n",
        "\n",
        "        detections = results[0].boxes\n",
        "\n",
        "        objects_info = []\n",
        "        for det in detections:\n",
        "            cls_id = int(det.cls)\n",
        "            cls_name = model.names[cls_id]\n",
        "            score = float(det.conf) * 100  # Уверенность в процентах\n",
        "\n",
        "            objects_info.append(PredictionResult(\n",
        "                class_id=cls_id,\n",
        "                class_name=cls_name,\n",
        "                score=score\n",
        "            ))\n",
        "\n",
        "        objects_info_all.append(ImageResult(\n",
        "            objects=objects_info,\n",
        "            processing_time=processing_time\n",
        "        ))\n",
        "\n",
        "    total_time = sum(processing_times)\n",
        "    average_time = total_time / len(processing_times)\n",
        "\n",
        "    return BatchResult(\n",
        "        results=objects_info_all,\n",
        "        total_processing_time=total_time,\n",
        "        average_processing_time=average_time\n",
        "    )\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     import uvicorn\n",
        "#     uvicorn.run(app, host=\"0.0.0.0\", port=8090)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPNhY_5po6PP",
        "outputId": "a6fc83cb-20da-4699-d74e-7b8a88bb3527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting fastapiapp.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# '1. Создайте виртуальную машину' и '3. Проведите тестирования обращения к Вашей моделе, развернутой на WSGI и на ASGI серверах'"
      ],
      "metadata": {
        "id": "Zt0aCCjDPNDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# Убеждаемся, что нет запущенных экземпляров gunicorn\n",
        "os.system('pkill gunicorn')\n",
        "\n",
        "!nohup gunicorn --bind 0.0.0.0:8000 flaskapp:app &\n",
        "\n",
        "# Задержка для запуска сервера\n",
        "time.sleep(5)\n",
        "\n",
        "url = 'http://0.0.0.0:8000/predict'\n",
        "image_folder = '/content/test_images'\n",
        "\n",
        "# Получаем список всех изображений в папке\n",
        "image_paths = glob.glob(os.path.join(image_folder, '*'))\n",
        "\n",
        "# Переменная для сохранения результатов\n",
        "results_summary = []\n",
        "\n",
        "# Отправляем изображения на сервер по одному\n",
        "for image_path in image_paths:\n",
        "    with open(image_path, 'rb') as f:\n",
        "        files = {'images': f}\n",
        "        response = requests.post(url, files=files)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        results_summary.append(data)\n",
        "        print(f'Results for {image_path}:')\n",
        "        for obj in data['results'][0]['objects']:\n",
        "            print(f\"Класс: {obj['class_name']}, Вероятность: {obj['score']:.2f}%\")\n",
        "        print(f\"Время обработки этого изображения: {data['results'][0]['processing_time']:.2f} секунд\\n\")\n",
        "    else:\n",
        "        print(f\"Обработка ошибок {image_path}: {response.text}\")\n",
        "\n",
        "# Выводим общую информацию по скорости обработки всех изображений\n",
        "total_time_flask = sum([res['total_processing_time'] for res in results_summary])\n",
        "average_time = total_time_flask / len(results_summary)\n",
        "\n",
        "print(f\"Время обработки всех изображений: {total_time_flask:.2f} сек\")\n",
        "print(f\"Среднее время обработки одного изображения: {average_time:.2f} сек\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rApcKzbnl4V7",
        "outputId": "f7bd074a-856a-45b9-951f-6f8db3d2f04b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "Results for /content/test_images/10.jpg:\n",
            "Класс: truck, Вероятность: 93.97%\n",
            "Время обработки этого изображения: 6.95 секунд\n",
            "\n",
            "Results for /content/test_images/1.jpg:\n",
            "Класс: airplane, Вероятность: 96.14%\n",
            "Время обработки этого изображения: 3.01 секунд\n",
            "\n",
            "Results for /content/test_images/4.jpg:\n",
            "Класс: cat, Вероятность: 96.81%\n",
            "Класс: couch, Вероятность: 54.19%\n",
            "Время обработки этого изображения: 2.98 секунд\n",
            "\n",
            "Results for /content/test_images/8.jpg:\n",
            "Класс: horse, Вероятность: 94.93%\n",
            "Время обработки этого изображения: 4.49 секунд\n",
            "\n",
            "Results for /content/test_images/5.jpg:\n",
            "Класс: sheep, Вероятность: 69.74%\n",
            "Время обработки этого изображения: 3.39 секунд\n",
            "\n",
            "Results for /content/test_images/3.jpg:\n",
            "Класс: bird, Вероятность: 96.41%\n",
            "Время обработки этого изображения: 3.01 секунд\n",
            "\n",
            "Results for /content/test_images/9.jpg:\n",
            "Класс: boat, Вероятность: 87.01%\n",
            "Время обработки этого изображения: 5.75 секунд\n",
            "\n",
            "Results for /content/test_images/6.jpg:\n",
            "Класс: dog, Вероятность: 97.93%\n",
            "Время обработки этого изображения: 3.80 секунд\n",
            "\n",
            "Results for /content/test_images/7.jpg:\n",
            "Класс: bird, Вероятность: 80.95%\n",
            "Время обработки этого изображения: 2.98 секунд\n",
            "\n",
            "Results for /content/test_images/2.jpg:\n",
            "Класс: car, Вероятность: 96.88%\n",
            "Время обработки этого изображения: 3.01 секунд\n",
            "\n",
            "Время обработки всех изображений: 39.37 сек\n",
            "Среднее время обработки одного изображения: 3.94 сек\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# Проверяем, что нет запущенных экземпляров uvicorn\n",
        "os.system('pkill uvicorn')\n",
        "\n",
        "# Запускаем сервер FastAPI с помощью uvicorn\n",
        "!nohup uvicorn --port 8090 fastapiapp:app &\n",
        "\n",
        "# Задержка для запуска сервера\n",
        "time.sleep(5)\n",
        "\n",
        "url = 'http://127.0.0.1:8090/predict'\n",
        "image_folder = '/content/test_images'\n",
        "\n",
        "# Получаем список всех изображений в папке\n",
        "image_paths = glob.glob(os.path.join(image_folder, '*'))\n",
        "\n",
        "# Переменная для сохранения результатов\n",
        "fastapi_results_summary = []\n",
        "\n",
        "# Отправляем изображения на сервер по одному\n",
        "files = [('images', (os.path.basename(image_path), open(image_path, 'rb'), 'image/jpeg')) for image_path in image_paths]\n",
        "response = requests.post(url, files=files)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    fastapi_results_summary.append(data)\n",
        "    for i, res in enumerate(data['results']):\n",
        "        print(f'Results for image {i+1}:')\n",
        "        for obj in res['objects']:\n",
        "            print(f\"Класс: {obj['class_name']}, Вероятность: {obj['score']:.2f}%\")\n",
        "        print(f\"Время обработки этого изображения: {res['processing_time']:.2f} seconds\\n\")\n",
        "else:\n",
        "    print(f\"Error processing images: {response.text}\")\n",
        "\n",
        "# Выводим общую информацию по скорости обработки всех изображений\n",
        "total_time = data['total_processing_time']\n",
        "average_time = data['average_processing_time']\n",
        "\n",
        "print(f\"Время обработки всех изображений: {total_time:.2f} сек\")\n",
        "print(f\"Среднее время обработки одного изображения: {average_time:.2f} сек\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv-JFmGuo6Lz",
        "outputId": "2ba33190-de5d-4d07-b112-a85c16eab9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "Results for image 1:\n",
            "Класс: truck, Вероятность: 93.97%\n",
            "Время обработки этого изображения: 6.25 seconds\n",
            "\n",
            "Results for image 2:\n",
            "Класс: airplane, Вероятность: 96.14%\n",
            "Время обработки этого изображения: 3.00 seconds\n",
            "\n",
            "Results for image 3:\n",
            "Класс: cat, Вероятность: 96.81%\n",
            "Класс: couch, Вероятность: 54.19%\n",
            "Время обработки этого изображения: 3.70 seconds\n",
            "\n",
            "Results for image 4:\n",
            "Класс: horse, Вероятность: 94.93%\n",
            "Время обработки этого изображения: 3.79 seconds\n",
            "\n",
            "Results for image 5:\n",
            "Класс: sheep, Вероятность: 69.74%\n",
            "Время обработки этого изображения: 2.93 seconds\n",
            "\n",
            "Results for image 6:\n",
            "Класс: bird, Вероятность: 96.41%\n",
            "Время обработки этого изображения: 2.51 seconds\n",
            "\n",
            "Results for image 7:\n",
            "Класс: boat, Вероятность: 87.01%\n",
            "Время обработки этого изображения: 3.66 seconds\n",
            "\n",
            "Results for image 8:\n",
            "Класс: dog, Вероятность: 97.93%\n",
            "Время обработки этого изображения: 4.30 seconds\n",
            "\n",
            "Results for image 9:\n",
            "Класс: bird, Вероятность: 80.95%\n",
            "Время обработки этого изображения: 2.92 seconds\n",
            "\n",
            "Results for image 10:\n",
            "Класс: car, Вероятность: 96.88%\n",
            "Время обработки этого изображения: 2.96 seconds\n",
            "\n",
            "Время обработки всех изображений: 36.02 сек\n",
            "Среднее время обработки одного изображения: 3.60 сек\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# '4. Ответом на ДЗ может быть таблица с результатами тестирования'"
      ],
      "metadata": {
        "id": "0_eBNIOPP3SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "comparison_data = {\n",
        "    'Сервер': ['Gunicorn', 'Uvicorn'],\n",
        "    'Время затраченное на обработку батча фотографий (s)': [\n",
        "        total_time_flask,\n",
        "        total_time\n",
        "    ]}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(comparison_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byfjZopHOzxI",
        "outputId": "896433e7-b6fb-48c0-917d-d98f64d7d14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Сервер  Время затраченное на обработку батча фотографий (s)\n",
            "0  Gunicorn                                          39.371388  \n",
            "1   Uvicorn                                          36.022598  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тесты"
      ],
      "metadata": {
        "id": "rymdHblyixLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file flaskapp1.py\n",
        "from flask import Flask, request, jsonify\n",
        "from ultralytics import YOLO\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "model = YOLO(\"yolov9e.pt\")\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if 'images' in request.files:\n",
        "        images = request.files.getlist('images')\n",
        "\n",
        "        for img in images:\n",
        "            # Получаем предсказания модели\n",
        "            model(img.read())\n",
        "\n",
        "        return jsonify({'message': 'Predictions completed'})\n",
        "\n",
        "    return jsonify({'error': 'No images provided'}), 400\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol7J3DdClXRm",
        "outputId": "b2351c2d-7cd9-4672-ee70-ca8219cdab9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting flaskapp1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# Убеждаемся, что нет запущенных экземпляров gunicorn\n",
        "os.system('pkill gunicorn')\n",
        "\n",
        "# Запускаем сервер\n",
        "!nohup gunicorn --bind 0.0.0.0:8000 flaskapp1:app &\n",
        "\n",
        "# Задержка для запуска сервера\n",
        "time.sleep(5)\n",
        "\n",
        "url = 'http://0.0.0.0:8000/predict'\n",
        "image_folder = '/content/test_images'\n",
        "\n",
        "# Получаем список всех изображений в папке\n",
        "image_paths = glob.glob(os.path.join(image_folder, '*'))\n",
        "\n",
        "total_start_time = time.time()\n",
        "\n",
        "# Отправляем изображения на сервер по одному\n",
        "for image_path in image_paths:\n",
        "    start_time = time.time()\n",
        "    with open(image_path, 'rb') as f:\n",
        "        files = {'images': f}\n",
        "        response = requests.post(url, files=files)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(f\"Response for {image_path}: {response.json()}\")\n",
        "    else:\n",
        "        print(f\"Error for {image_path}: {response.text}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Processing time for {image_path}: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "total_end_time = time.time()\n",
        "print(f\"Total processing time: {total_end_time - total_start_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "zhAZ_H1VmCEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "377915b1-91ca-4c05-afe2-0680220171a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "Error for /content/test_images/2.jpg: <!doctype html>\n",
            "<html lang=en>\n",
            "<title>500 Internal Server Error</title>\n",
            "<h1>Internal Server Error</h1>\n",
            "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
            "\n",
            "Processing time for /content/test_images/2.jpg: 2.72 seconds\n",
            "Error for /content/test_images/8.jpg: <!doctype html>\n",
            "<html lang=en>\n",
            "<title>500 Internal Server Error</title>\n",
            "<h1>Internal Server Error</h1>\n",
            "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
            "\n",
            "Processing time for /content/test_images/8.jpg: 0.01 seconds\n",
            "Error for /content/test_images/7.jpg: <!doctype html>\n",
            "<html lang=en>\n",
            "<title>500 Internal Server Error</title>\n",
            "<h1>Internal Server Error</h1>\n",
            "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
            "\n",
            "Processing time for /content/test_images/7.jpg: 0.00 seconds\n",
            "Error for /content/test_images/6.jpg: <!doctype html>\n",
            "<html lang=en>\n",
            "<title>500 Internal Server Error</title>\n",
            "<h1>Internal Server Error</h1>\n",
            "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
            "\n",
            "Processing time for /content/test_images/6.jpg: 0.01 seconds\n",
            "Error for /content/test_images/4.jpg: <!doctype html>\n",
            "<html lang=en>\n",
            "<title>500 Internal Server Error</title>\n",
            "<h1>Internal Server Error</h1>\n",
            "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
            "\n",
            "Processing time for /content/test_images/4.jpg: 0.01 seconds\n",
            "Error for /content/test_images/10.jpg: <!doctype html>\n",
            "<html lang=en>\n",
            "<title>500 Internal Server Error</title>\n",
            "<h1>Internal Server Error</h1>\n",
            "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
            "\n",
            "Processing time for /content/test_images/10.jpg: 0.01 seconds\n",
            "Error for /content/test_images/5.jpg: <!doctype html>\n",
            "<html lang=en>\n",
            "<title>500 Internal Server Error</title>\n",
            "<h1>Internal Server Error</h1>\n",
            "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
            "\n",
            "Processing time for /content/test_images/5.jpg: 0.00 seconds\n",
            "Error for /content/test_images/3.jpg: <!doctype html>\n",
            "<html lang=en>\n",
            "<title>500 Internal Server Error</title>\n",
            "<h1>Internal Server Error</h1>\n",
            "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
            "\n",
            "Processing time for /content/test_images/3.jpg: 0.00 seconds\n",
            "Error for /content/test_images/9.jpg: <!doctype html>\n",
            "<html lang=en>\n",
            "<title>500 Internal Server Error</title>\n",
            "<h1>Internal Server Error</h1>\n",
            "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
            "\n",
            "Processing time for /content/test_images/9.jpg: 0.00 seconds\n",
            "Error for /content/test_images/1.jpg: <!doctype html>\n",
            "<html lang=en>\n",
            "<title>500 Internal Server Error</title>\n",
            "<h1>Internal Server Error</h1>\n",
            "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
            "\n",
            "Processing time for /content/test_images/1.jpg: 0.01 seconds\n",
            "Total processing time: 2.77 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install ultralytics"
      ],
      "metadata": {
        "id": "4nfJavADmdN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b956c89c-c99f-4504-a2b2-c880a1fd63ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip uninstall ultralytics -y"
      ],
      "metadata": {
        "id": "OCpqIjmAoIlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install ultralytics[yolo]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HikbvkQ1nmpo",
        "outputId": "6eb031be-2a93-4a88-bf20-4e3d969d0e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: ultralytics 8.2.28 does not provide the extra 'yolo'\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip uninstall ultralytics -y\n",
        "!pip install ultralytics==8.0.14[yolo]"
      ],
      "metadata": {
        "id": "Pdqw4RTbn7vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Данные из учебного ноутбука:"
      ],
      "metadata": {
        "id": "LTyI_Si9PxcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gunicorn"
      ],
      "metadata": {
        "id": "-cAJRPgg045S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf15b353-b2fa-432f-fb14-6df34cb26a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gunicorn\n",
            "  Downloading gunicorn-22.0.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gunicorn) (24.0)\n",
            "Installing collected packages: gunicorn\n",
            "Successfully installed gunicorn-22.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузите модель"
      ],
      "metadata": {
        "id": "8qakiDecNn4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "# Загрузка из облака yandexcloud\n",
        "gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l6/model_fmr_all.h5', None, quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lx4M5MB91bTH",
        "outputId": "c280f757-70ac-4465-9452-4e3c1cf8bf7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model_fmr_all.h5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузите и распакуйте архив с примерами картинок"
      ],
      "metadata": {
        "id": "YhpsJk3mO5-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "# Загрузка примеров для распознавания (классификации)\n",
        "gdown.download('https://storage.yandexcloud.net/aiueducation/Content/knowledge/test_images.zip', None, quiet=True)\n",
        "# Распаковка архива\n",
        "!unzip -qo test_images.zip"
      ],
      "metadata": {
        "id": "Y_p9HYeg2jGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте файл `flaskapp.py`, запустив ячейку с магической командой: `%%file`"
      ],
      "metadata": {
        "id": "CHzi7Pm-Rf5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file flaskapp.py\n",
        "import io\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "from flask import Flask, request, jsonify\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "import time\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Загрузка модели\n",
        "model = load_model('model_fmr_all.h5')\n",
        "\n",
        "classes = {0: 'самолет',\n",
        "            1: 'автомобиль',\n",
        "            2: 'птица',\n",
        "            3: 'кот',\n",
        "            4: 'олень',\n",
        "            5: 'собака',\n",
        "            6: 'лягушка',\n",
        "            7: 'лошадь',\n",
        "            8: 'корабль',\n",
        "            9: 'грузовик'}\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if request.files.get('image'):\n",
        "        time.sleep(1)\n",
        "        image = request.files['image'].read()\n",
        "        image = Image.open(io.BytesIO(image))\n",
        "        if image.mode != \"RGB\":\n",
        "          image = image.convert(\"RGB\")\n",
        "        image = image.resize((32, 32))\n",
        "        image = np.array(image, dtype='float64') / 255\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "\n",
        "        preds = model.predict(image)\n",
        "        class_id = np.argmax(preds)\n",
        "\n",
        "        return jsonify({'class': classes[int(class_id)]})\n",
        "\n",
        "    return jsonify({'error': 'No image provided'}), 400\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HJow31l0cEV",
        "outputId": "8e88bc51-c5f8-421e-bbc4-c095beb0ad6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing flaskapp.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если запущен сервер, то закройте его."
      ],
      "metadata": {
        "id": "H-LKkpP0OGi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill gunicorn"
      ],
      "metadata": {
        "id": "Lcj0zsK81afI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запустите сервер"
      ],
      "metadata": {
        "id": "_FIJtJOxOUBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup gunicorn --bind 0.0.0.0:8000 flaskapp:app &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMlA-qvG0xlU",
        "outputId": "ce7cde10-1ea6-4496-8bab-528d5266c09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отправьте тестовую картинку на сервер для распознавания"
      ],
      "metadata": {
        "id": "fXMe7U-0PJk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://0.0.0.0:8000/predict'\n",
        "image_path = '/content/test_images/2.jpg'\n",
        "\n",
        "import requests\n",
        "\n",
        "# Открываем файл \"image.jpg\" в режиме бинарного чтения\n",
        "with open(image_path, 'rb') as f:\n",
        "    # Создаем словарь данных для отправки\n",
        "    files = {'image': f}\n",
        "\n",
        "    # Отправляем POST-запрос на сервер\n",
        "    response = requests.post(url, files=files)\n",
        "\n",
        "# Проверяем статус ответа\n",
        "if response.status_code == 200:\n",
        "    # Распечатываем полученные данные\n",
        "    data = response.json()\n",
        "    print('Class ID:', data['class'])\n",
        "else:\n",
        "    print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaM2m_2wyqes",
        "outputId": "340d18b9-61d8-4ec3-8ead-b66f9f083ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class ID: автомобиль\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Установите библиотеки `fastapi python-multipart` и сервер `uvicorn`"
      ],
      "metadata": {
        "id": "ZWbJ6BqZQwK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install fastapi python-multipart uvicorn"
      ],
      "metadata": {
        "id": "pCOynkCF1GQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте файл `fastapiapp.py`, запустив ячейку с магической командой: `%%file`"
      ],
      "metadata": {
        "id": "BZ1JNflhR1VM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file fastapiapp.py\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from tensorflow.keras.models import load_model\n",
        "import time\n",
        "from starlette.responses import JSONResponse\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Загрузка модели\n",
        "model = load_model('model_fmr_all.h5')\n",
        "\n",
        "classes = {0: 'самолет',\n",
        "            1: 'автомобиль',\n",
        "            2: 'птица',\n",
        "            3: 'кот',\n",
        "            4: 'олень',\n",
        "            5: 'собака',\n",
        "            6: 'лягушка',\n",
        "            7: 'лошадь',\n",
        "            8: 'корабль',\n",
        "            9: 'грузовик'}\n",
        "\n",
        "@app.post('/predict')\n",
        "async def predict(image: UploadFile = File(...)):\n",
        "    time.sleep(1)\n",
        "    image_bytes = await image.read()\n",
        "    image = Image.open(io.BytesIO(image_bytes))\n",
        "    if image.mode != \"RGB\":\n",
        "        image = image.convert(\"RGB\")\n",
        "    image = image.resize((32, 32))\n",
        "    image = np.array(image, dtype='float64') / 255\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    preds = model.predict(image)\n",
        "    class_id = np.argmax(preds)\n",
        "\n",
        "    response_data = {'class': classes[int(class_id)]}\n",
        "    return response_data"
      ],
      "metadata": {
        "id": "EwSstwrDv-Ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff98f6e2-3f4c-4793-9571-cba11e81dbfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing fastapiapp.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если запущен сервер, то закройте его."
      ],
      "metadata": {
        "id": "nmZ7ZYSCQdB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill uvicorn"
      ],
      "metadata": {
        "id": "khtAJwtM1yjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запустите сервер"
      ],
      "metadata": {
        "id": "kEm1VJQPQdCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup uvicorn --port 8090 fastapiapp:app &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd792qol1Fx8",
        "outputId": "ca0d33cf-0793-4b1c-f6a1-73797dc2eff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверьте список запущенных процессов"
      ],
      "metadata": {
        "id": "xbJytGE0UeCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9Nc0JVDUbgk",
        "outputId": "a30c11a2-f00f-4143-9e65-e0709a5b5500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    PID TTY          TIME CMD\n",
            "      1 ?        00:00:00 docker-init\n",
            "      7 ?        00:00:04 node\n",
            "     17 ?        00:00:00 oom_monitor.sh\n",
            "     19 ?        00:00:00 run.sh\n",
            "     21 ?        00:00:00 kernel_manager_\n",
            "     23 ?        00:00:00 tail\n",
            "     59 ?        00:00:08 python3 <defunct>\n",
            "     60 ?        00:00:01 colab-fileshim.\n",
            "     82 ?        00:00:04 jupyter-noteboo\n",
            "     83 ?        00:00:00 dap_multiplexer\n",
            "    171 ?        00:00:05 python3\n",
            "    210 ?        00:00:01 python3\n",
            "    427 ?        00:00:00 gunicorn\n",
            "    433 ?        00:00:06 gunicorn\n",
            "   2115 ?        00:00:00 language_servic\n",
            "   2120 ?        00:00:10 node\n",
            "   2178 ?        00:00:04 uvicorn\n",
            "   2201 ?        00:00:00 sleep\n",
            "   2205 ?        00:00:00 ps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отправьте тестовую картинку на сервер для распознавания. Предварительно, дождавшись запуска сервера."
      ],
      "metadata": {
        "id": "cAH4TzicQnZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://127.0.0.1:8090/predict'\n",
        "image_path = '/content/test_images/4.jpg'\n",
        "\n",
        "import requests\n",
        "\n",
        "# Открываем файл \"image.jpg\" в режиме бинарного чтения\n",
        "with open(image_path, 'rb') as f:\n",
        "    # Создаем словарь данных для отправки\n",
        "    files = {'image': f}\n",
        "\n",
        "    # Отправляем POST-запрос на сервер\n",
        "    response = requests.post(url, files=files)\n",
        "\n",
        "# Проверяем статус ответа\n",
        "if response.status_code == 200:\n",
        "    # Распечатываем полученные данные\n",
        "    data = response.json()\n",
        "    print('Class:', data['class'])\n",
        "else:\n",
        "  print('Error')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11gRgpT34t7O",
        "outputId": "5bc716b5-4ace-4495-c688-814d3e798954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: птица\n"
          ]
        }
      ]
    }
  ]
}